{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading libraries used throughout the notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading in the datasets from csv using pandas\n",
    "dfMockTest = pd.read_csv('TestResults/Formative_Mock_Test.csv', index_col = False)\n",
    "dfTest_1 = pd.read_csv('TestResults/Formative_Test_1.csv', index_col = False)\n",
    "dfTest_2 = pd.read_csv('TestResults/Formative_Test_2.csv', index_col = False)\n",
    "dfTest_3 = pd.read_csv('TestResults/Formative_Test_3.csv', index_col = False)\n",
    "dfTest_4 = pd.read_csv('TestResults/Formative_Test_4.csv', index_col = False)\n",
    "dfSumTest = pd.read_csv('TestResults/SumTest.csv', index_col = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform changes made throughout the datasets function\n",
    "def standard_changes(df):\n",
    "    \n",
    "    \"\"\"Function that adjusts consitent column headings\n",
    "    for all tests \"\"\"\n",
    "\n",
    "    # Remove leading and tailing whitespaces in column headings\n",
    "    df.columns.str.strip()\n",
    "    \n",
    "    # Remove unwanted columns from dataframe\n",
    "    df.drop(['State', 'Time taken'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Rename standard column headings in the datframe\n",
    "    df.rename(columns = {'research id':'research_id', 'Started on':'started_on', 'Completed':'completed'}, inplace = True)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the question and grade columns (varying elemetns by datset) \n",
    "def clean_questions(df):\n",
    "    \n",
    "    \"\"\"Function cleans the question and grade columns\n",
    "    of the given dataframes. This is achieved by:\n",
    "    - Splitting and storing total marks available from column heading\n",
    "    - Removing whitespaces to tidy column headings\n",
    "    - Rename all the columns to the new clean headings \"\"\"\n",
    "\n",
    "    # Splitting and storing total marks in relation to each question\n",
    "    col_split_index = df.columns.str.split(\"/\")\n",
    "    col_head = col_split_index[0] + col_split_index[1] + col_split_index[2]\n",
    "    col_head.append(col_split_index[3][0].lower())\n",
    "    q_marks = []\n",
    "    q_heading = []\n",
    "    \n",
    "    # Loop thorugh split column headings to fill 'question number' and 'marks available' vectors respectively\n",
    "    for i in range(4, len(col_split_index)):\n",
    "        q_heading.append(col_split_index[i][0])\n",
    "        q_marks.append(col_split_index[i][1])\n",
    "        i += 1\n",
    "        \n",
    "    # Remove whitespaces within question column heading (i.e \"Q 1\" to become \"Q1\") using loops\n",
    "    q_split = []\n",
    "    for j in q_heading:\n",
    "        q_split.append(j.split(\" \"))\n",
    "    \n",
    "    # Define vector which contains new clean column headings ('col_head')\n",
    "    q_split_index = []\n",
    "    for k in range(0,len(q_split)):\n",
    "        q_split_index.append(q_split[k][0] + q_split[k][1])\n",
    "        col_head.append(q_split_index[k])\n",
    "        k += 1       \n",
    "\n",
    "    # Rename the dataframe column headings using the vector 'col_head' defined above\n",
    "    for c in range(0,len(df.columns)):\n",
    "        df.rename(columns = {df.columns[c]:col_head[c]}, inplace = True)\n",
    "        c += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing and null values from data frame\n",
    "def remove_null(df):\n",
    "    \n",
    "    \"\"\"Function replaces null and '-' values with 0 \n",
    "    allowing for clean computation \"\"\"\n",
    "    \n",
    "    # Convert 'na' and blank (\"-\") values to 0 in preparation for value normalisation\n",
    "    df.fillna(0, inplace = True)\n",
    "    df.replace(to_replace = [\"-\"], value = 0, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to adjsut column classifications\n",
    "def adjust_col_types(df):\n",
    "    \n",
    "    \"\"\"Function to ensure correct classifications by:\n",
    "    - Converting numbers from strings to 'int64' format\n",
    "    - Converting dates to 'datetime64[ns]' format\n",
    "    - Converting marks to 'float64' format \"\"\"\n",
    "    \n",
    "    # Research ID to integer\n",
    "    df.loc[:,'research_id'] = df.loc[:,'research_id'].apply(pd.to_numeric).astype('int64')\n",
    "    \n",
    "    # Date cols to datetime format\n",
    "    df.loc[:,'started_on':'completed'] = df.loc[:,'started_on':'completed'].apply(pd.to_datetime)\n",
    "    \n",
    "    # Marks to floats format\n",
    "    df.loc[:,'grade':] = df.loc[:,'grade':].apply(pd.to_numeric).astype('float64')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lowest grade if duplicates exist function\n",
    "def remove_lowest_grade(df):\n",
    "    \n",
    "    \"\"\"Function removing any duplicate entries and \n",
    "    taking the highest grade value if the duplicate exists \"\"\"\n",
    "\n",
    "    df = df.sort_values(['grade'], ascending = False).drop_duplicates(['research_id'], keep = 'first')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Clean DataFrame Function\n",
    "def clean_data(df):\n",
    "    \n",
    "    \"\"\"Function to clean a given dataframe by:\n",
    "    - Making standard column changes in snake case format\n",
    "    - Clean variable column headings in snake case format\n",
    "    - Adjust na and blank values with 0 marks\n",
    "    - Ensure columns are in the correct datatype\n",
    "    - Call function to remove duplicate attmepts taking highest grade\n",
    "    - Order and return the final clean dataframe \"\"\"\n",
    "\n",
    "    # Call function for djustment to standard expected column headings\n",
    "    df = standard_changes(df)\n",
    "\n",
    "    # Call function for adjustment of variable columns for each dataset\n",
    "    df = clean_questions(df)\n",
    "    \n",
    "    # Call function to remove null values from the dataframe \n",
    "    df = remove_null(df)\n",
    "    \n",
    "    # Call classification adjustment function\n",
    "    df = adjust_col_types(df)\n",
    "    \n",
    "    # Call function to remove worst result if duplicates exist\n",
    "    df = remove_lowest_grade(df)\n",
    "    \n",
    "    # Order by student reference and return clean dataframe as output\n",
    "    df = df.sort_values(['research_id'], ascending = True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Normalise marks function\n",
    "def normalise_data(dfClean, dfOriginal):\n",
    "    \n",
    "    \"\"\"Function to normalise grades in the given data frame. \n",
    "    This function works by:\n",
    "    - Taking the clean and the original dataframe then;\n",
    "    - Cleaning the original to match standard changes\n",
    "    - Storing a list of total available marks per question\n",
    "    - Coverting the available marks list to floats\n",
    "    - Iterating through the question columns to normalise the values in each \n",
    "    - Finally order and return \"\"\"\n",
    "    \n",
    "    # Call standard changes function on the original dataframe to match clean data frame\n",
    "    standard_changes(dfOriginal)\n",
    "    \n",
    "    # Splitting and saving marks available for each question from original dataframe\n",
    "    grade_vector = []\n",
    "    col_split_index = dfOriginal.columns.str.split(\"/\")\n",
    "    \n",
    "    for i in range(dfClean.columns.get_loc('completed') + 1, len(col_split_index)):\n",
    "        grade_vector.append(col_split_index[i][1])\n",
    "        i += 1\n",
    "    \n",
    "    # Convert total available marks list from string to float (dividing by 100 to obtain raw mark value)\n",
    "    grade_vector[:] = pd.to_numeric(grade_vector[:], errors='coerce').astype('float64')/100\n",
    "    \n",
    "    # Iterate through columns performing value standardisation (making marks a percentage)\n",
    "    for m in range(dfClean.columns.get_loc('grade'), len(dfClean.columns)):\n",
    "        dfClean.iloc[:,m] = ((dfClean.iloc[:,m]/grade_vector[m - dfClean.columns.get_loc('grade')]))*100\n",
    "        m += 1\n",
    "    \n",
    "    # Order by student reference and return clean formatted dataframe as output\n",
    "    dfClean = dfClean.sort_values(['research_id'], ascending = True)\n",
    "    return dfClean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new names and call the clean data function for specified data frames\n",
    "\n",
    "# Creating a copy of the dfs\n",
    "dfCleanMockTest = dfMockTest.copy()\n",
    "dfCleanTest_1 = dfTest_1.copy()\n",
    "dfCleanTest_2 = dfTest_2.copy()\n",
    "dfCleanTest_3 = dfTest_3.copy()\n",
    "dfCleanTest_4 = dfTest_4.copy()\n",
    "dfCleanSumTest = dfSumTest.copy()\n",
    "\n",
    "dfCleanMockTest = clean_data(dfCleanMockTest)\n",
    "dfCleanTest_1 = clean_data(dfCleanTest_1)\n",
    "dfCleanTest_2 = clean_data(dfCleanTest_2)\n",
    "dfCleanTest_3 = clean_data(dfCleanTest_3)\n",
    "dfCleanTest_4 = clean_data(dfCleanTest_4)\n",
    "dfCleanSumTest = clean_data(dfCleanSumTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new names and call the normalising function for specified data frames\n",
    "\n",
    "# Creating a copy of the dfs\n",
    "dfFormattedCleanMockTest = dfCleanMockTest.copy()\n",
    "dfFormattedCleanTest_1 = dfCleanTest_1.copy()\n",
    "dfFormattedCleanTest_2 = dfCleanTest_2.copy()\n",
    "dfFormattedCleanTest_3 = dfCleanTest_3.copy()\n",
    "dfFormattedCleanTest_4 = dfCleanTest_4.copy()\n",
    "dfFormattedCleanSumTest = dfCleanSumTest.copy()\n",
    "\n",
    "dfFormattedCleanMockTest = normalise_data(dfFormattedCleanMockTest, dfMockTest)\n",
    "dfFormattedCleanTest_1 = normalise_data(dfFormattedCleanTest_1, dfTest_1)\n",
    "dfFormattedCleanTest_2 = normalise_data(dfFormattedCleanTest_2, dfTest_2)\n",
    "dfFormattedCleanTest_3 = normalise_data(dfFormattedCleanTest_3, dfTest_3)\n",
    "dfFormattedCleanTest_4 = normalise_data(dfFormattedCleanTest_4, dfTest_4)\n",
    "dfFormattedCleanSumTest = normalise_data(dfFormattedCleanSumTest, dfSumTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     research_id          started_on           completed   grade     Q1  \\\n",
      "32             1 2018-11-14 09:50:00 2018-11-14 10:51:00   66.00  100.0   \n",
      "45             2 2018-11-14 09:50:00 2018-11-14 10:31:00  100.00  100.0   \n",
      "7              3 2018-11-14 09:50:00 2018-11-14 10:51:00   63.75  100.0   \n",
      "120            4 2018-11-14 11:09:00 2018-11-14 12:10:00   51.00    0.0   \n",
      "143            5 2018-11-14 11:10:00 2018-11-14 12:11:00   46.63  100.0   \n",
      "..           ...                 ...                 ...     ...    ...   \n",
      "68           152 2018-11-14 09:50:00 2018-11-14 10:51:00   72.00  100.0   \n",
      "53           153 2018-11-14 09:50:00 2018-11-14 10:51:00   45.00  100.0   \n",
      "78           154 2018-11-14 11:09:00 2018-11-14 12:10:00   94.00  100.0   \n",
      "14           155 2018-11-14 09:50:00 2018-11-14 10:51:00   95.00  100.0   \n",
      "3            156 2018-11-14 09:50:00 2018-11-14 10:51:00   64.00  100.0   \n",
      "\n",
      "        Q2     Q3     Q4     Q5     Q6     Q7          Q8          Q9    Q10  \\\n",
      "32   100.0  100.0  100.0   50.0  100.0  100.0  100.000000   26.666667    0.0   \n",
      "45   100.0  100.0  100.0  100.0  100.0  100.0  100.000000  100.000000  100.0   \n",
      "7    100.0  100.0  100.0  100.0  100.0  100.0   25.000000  100.000000    0.0   \n",
      "120  100.0  100.0  100.0    0.0  100.0  100.0  100.000000    0.000000    0.0   \n",
      "143  100.0  100.0  100.0    0.0  100.0  100.0   37.533333    0.000000    0.0   \n",
      "..     ...    ...    ...    ...    ...    ...         ...         ...    ...   \n",
      "68   100.0  100.0  100.0  100.0  100.0  100.0  100.000000   66.666667   20.0   \n",
      "53   100.0  100.0  100.0    0.0  100.0  100.0    0.000000   26.666667    0.0   \n",
      "78   100.0  100.0  100.0  100.0  100.0  100.0  100.000000  100.000000  100.0   \n",
      "14   100.0  100.0  100.0  100.0  100.0  100.0  100.000000  100.000000  100.0   \n",
      "3    100.0  100.0  100.0  100.0  100.0  100.0    0.000000  100.000000    0.0   \n",
      "\n",
      "       Q11    Q12    Q13  \n",
      "32   100.0    0.0    0.0  \n",
      "45   100.0  100.0  100.0  \n",
      "7      0.0    0.0    0.0  \n",
      "120    0.0    0.0    0.0  \n",
      "143    0.0    0.0    0.0  \n",
      "..     ...    ...    ...  \n",
      "68     0.0    0.0    0.0  \n",
      "53     0.0    0.0    0.0  \n",
      "78   100.0  100.0    0.0  \n",
      "14   100.0    0.0  100.0  \n",
      "3    100.0    0.0    0.0  \n",
      "\n",
      "[153 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example of Formatted Clean Dataframe for SumTest\n",
    "print(dfFormattedCleanSumTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Define SQL connection\n",
    "results = sqlite3.connect('Resultdatabase.db')\n",
    "\n",
    "# Send data frames to SQL tables\n",
    "dfFormattedCleanMockTest.to_sql(\"dfFormattedCleanMockTest\", results, if_exists='replace', index = False)\n",
    "dfFormattedCleanTest_1.to_sql(\"dfFormattedCleanTest_1\", results, if_exists='replace', index = False)\n",
    "dfFormattedCleanTest_2.to_sql(\"dfFormattedCleanTest_2\", results, if_exists='replace', index = False)\n",
    "dfFormattedCleanTest_3.to_sql(\"dfFormattedCleanTest_3\", results, if_exists='replace', index = False)\n",
    "dfFormattedCleanTest_4.to_sql(\"dfFormattedCleanTest_4\", results, if_exists='replace', index = False)\n",
    "dfFormattedCleanSumTest.to_sql(\"dfFormattedCleanSumTest\", results, if_exists='replace', index = False)\n",
    "\n",
    "# Autosave (commit) and close the database file \n",
    "results.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a function to randomise and overwrite marks\n",
    "def modify_data(dbFile, index_no, question_no):\n",
    "    \n",
    "    \"\"\"Function creates a random vector to represent the \n",
    "    number of indexes to modify, which questions and how many \n",
    "    to modify. It also randomly assigns new grades then finally\n",
    "    updates the database file storing the results.\"\"\"\n",
    "\n",
    "    # Create random number vector of specified ('index_no') number of unique values between 0 and 150\n",
    "    flag_0 = True\n",
    "    while flag_0 == True:   \n",
    "        indicies = np.random.randint(low = 0, high = 150, size = index_no)\n",
    "        indicies = list(dict.fromkeys(indicies))\n",
    "        indicies.sort()\n",
    "        if len(indicies) != index_no:\n",
    "            flag_0 = True\n",
    "        else:\n",
    "            flag_0 = False\n",
    "            break \n",
    "\n",
    "    # Create unique random column index for specified number ('question_no') of questions in order to edit the results\n",
    "    flag_1 = True\n",
    "    while flag_1 == True:\n",
    "        questions = np.random.randint(low = 4, high = 17, size = question_no)\n",
    "        questions = list(dict.fromkeys(questions))\n",
    "        questions.sort()\n",
    "        if len(questions) != question_no:\n",
    "            flag_1 = True\n",
    "        else:\n",
    "            flag_1 = False\n",
    "            break \n",
    "\n",
    "\n",
    "    # Create a new dataframe storing random grades as percentages\n",
    "    mod_grade_col = []\n",
    "    for c in range(0, question_no):\n",
    "        mod_grade_col.append(str('mod' + str(c)))\n",
    "        c += 1\n",
    "\n",
    "    mod_grades = pd.DataFrame(index = np.arange(index_no), columns = mod_grade_col)    \n",
    "    for j in range(0,len(questions)):\n",
    "        mod_grades.iloc[:,j] = np.round_(np.random.uniform(low = 0, high = 1, size = index_no), decimals = 3)*100\n",
    "\n",
    "\n",
    "    # Update the main dataframe with the modified values\n",
    "    results = sqlite3.connect(dbFile)\n",
    "\n",
    "    dfFormattedCleanSumTest = pd.read_sql('SELECT * FROM dfFormattedCleanSumTest', results)\n",
    "    \n",
    "    for i in range(0,len(mod_grades)):\n",
    "        for j in range(0,len(mod_grades.columns)):\n",
    "            dfFormattedCleanSumTest.iloc[indicies[i], questions[j]] = mod_grades.iloc[i,j]\n",
    "            \n",
    "        new_total = dfFormattedCleanSumTest.iloc[indicies[i], dfFormattedCleanSumTest.columns.get_loc('grade')+1:].sum()\n",
    "        total_qs = len(dfFormattedCleanSumTest.columns) - (dfFormattedCleanSumTest.columns.get_loc('grade')+1)\n",
    "\n",
    "        dfFormattedCleanSumTest.iloc[indicies[i], dfFormattedCleanSumTest.columns.get_loc('grade')] = new_total / total_qs\n",
    "    \n",
    "    \n",
    "    #Save the modified data over original dataframe\n",
    "    dfFormattedCleanSumTest.to_sql(\"dfFormattedCleanSumTest\", results, if_exists='replace', index = False)\n",
    "\n",
    "    # Autosave (commit) and close the database file \n",
    "    results.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call modify data function for 20 rows changing marks for a random 3 questions\n",
    "modify_data('Resultdatabase.db', 20, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   research_id           started_on            completed      grade    Q1  \\\n",
      "0          122  2018-10-17 10:15:00  2018-10-18 13:05:00  91.428571  60.0   \n",
      "\n",
      "      Q2     Q3     Q4    Q5     Q6  \n",
      "0  100.0  100.0  100.0  80.0  100.0  \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Check database saves values\n",
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "results = sqlite3.connect('Resultdatabase.db')\n",
    "\n",
    "modified = pd.read_sql('SELECT * FROM dfFormattedCleanTest_2 WHERE research_id == 122', results)\n",
    "print(modified.iloc[:, :])\n",
    "print(modified.empty)\n",
    "\n",
    "results.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
